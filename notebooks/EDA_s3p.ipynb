{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is a quick exploration of the content and preprocessing of the raw s3p dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/01_raw/s3p.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = df.select_dtypes(include=\"number\")\n",
    "print(\"N° numerical cols:\", len(numerical.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(exclude=\"number\")\n",
    "print(\"N° categorical cols:\", len(categorical.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore cardinality in dataset\n",
    "cardinal_cols = df.nunique().sort_values(ascending=False)\n",
    "cardinal_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select cardinal columns to delete (columns > 80% uniques values)\n",
    "\n",
    "card_to_del = cardinal_cols[cardinal_cols > 0.8 * len(df)].index\n",
    "card_to_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete high cardinal columns. This columns doesn't good for create models\n",
    "\n",
    "df.drop(columns=card_to_del, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore unique values ​​of some interesting variables\n",
    "df[\"tipoFalta\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show null values to take actions\n",
    "nulls = df.isnull().sum()\n",
    "nulls.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete columns with high null values (null > 70%)\n",
    "\n",
    "cols_delete = nulls[nulls > 0.7 * len(df)].index\n",
    "cols_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with many null values\n",
    "df.drop(columns=cols_delete, axis=1, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore large text columns \n",
    "df[\"objetoContrato\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore not good parsed (json to csv) columns for take actions\n",
    "df[\"tipoSancion\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, transformations and cleaning are carried out on the columns of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns, remove (\".\") dot structure created with json_normalize to avoid confusion\n",
    "import re\n",
    "columns = df2.columns\n",
    "\n",
    "for column in columns:\n",
    "    # replace . to _ using re library\n",
    "    new_column = re.sub(r'\\.', '_', column)\n",
    "    df2 = df2.rename(columns={column: new_column})\n",
    "\n",
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop not interesting columns. Names are not good for predictions,\n",
    "# 'institucionDependencia_siglas' is high correlate to 'institucionDependencia_nombre'\n",
    "# and 'resolucion_fechaNotificacion' is a field that does not provide significant \n",
    "# information in a low complexity analysis\n",
    "\n",
    "not_interesting_cols = [\n",
    "    \"institucionDependencia_siglas\",\n",
    "    \"responsableSancion_nombres\",\n",
    "    \"responsableSancion_primerApellido\",\n",
    "    \"responsableSancion_segundoApellido\",\n",
    "    \"resolucion_fechaNotificacion\"\n",
    "]\n",
    "df2.drop(not_interesting_cols, axis=1, inplace=True)\n",
    "df2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting fechaCaptura column to exclude T HH:mm:ss\n",
    "\n",
    "def removeTime(string:str):\n",
    "    return string.split(\"T\")[0]\n",
    "\n",
    "\n",
    "df3[\"fechaCaptura\"] = df3[\"fechaCaptura\"].apply(removeTime)\n",
    "df3[\"fechaCaptura\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values in each column with itself mode value\n",
    "\n",
    "for column in df3.columns:\n",
    "    df3[column].fillna(df3[column].mode()[0], inplace=True)\n",
    "\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with '-' in inhabilitacion_fechaFinal and inhabilitacion_fechaInicial columns\n",
    "df3.drop(df3[df3['inhabilitacion_fechaFinal'] == '-'].index, inplace=True)\n",
    "df3.drop(df3[df3['inhabilitacion_fechaInicial'] == '-'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to standardize the datetime format across all columns with this date type\n",
    "def formatDatetime(string:str):\n",
    "    formats = ['%Y-%m-%d', '%d-%b-%Y', '%d-%m-%Y']\n",
    "    for format in formats:\n",
    "        try:\n",
    "            return datetime.strptime(string, format).strftime('%Y/%m/%d')\n",
    "        except Exception as e:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format date type columns to the desired format\n",
    "df3['inhabilitacion_fechaInicial'] = df3['inhabilitacion_fechaInicial'].apply(formatDatetime)\n",
    "df3['inhabilitacion_fechaFinal'] = df3['inhabilitacion_fechaFinal'].apply(formatDatetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a bug in conversion datetime format (anomaly in datetime to formatting '%d-%b-%Y', unresolved)\n",
    "# rows with new null values in above re-formatted columns\n",
    "#df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with new null values (anomaly in datetime to formatting '%d-%b-%Y')\n",
    "df3.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index of dataframe\n",
    "df3.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change datatype from date columns (object to datetype)\n",
    "date_cols = [col for col in df3.columns if \"fecha\" in col]\n",
    "df3[date_cols] = df3[date_cols].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sanction duration in days ans assing it to new column 'tiempo_sancion'\n",
    "\n",
    "df3[\"tiempo_sancion\"] = (df3['inhabilitacion_fechaFinal'] - df3['inhabilitacion_fechaInicial']).dt.days\n",
    "df3[\"tiempo_sancion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform resolution_url column values to binary label (int type) according if It has url or no.\n",
    "\n",
    "df4[\"resolucion_url\"] = df4[\"resolucion_url\"].apply(lambda x: 1 if \"https:\" in x else 0)\n",
    "df4[\"resolucion_url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"tipoSancion\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create mapper function from tipoSancion column\n",
    "\n",
    "def mapperSanctions(string:str):\n",
    "    if 'INHABILITA' in string and 'MULT' not in string:\n",
    "        return 'inhabilitado'\n",
    "    elif 'INHABILITA' not in string and 'MULT' in string:\n",
    "        return 'multado'\n",
    "    elif 'INHABILITA' in string and 'MULT' in string:\n",
    "        return 'multado e inhabilitado'\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "\n",
    "df4[\"tipoSancion\"] = df4[\"tipoSancion\"].apply(mapperSanctions)\n",
    "df4[\"tipoSancion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4[\"tipoSancion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding categorical columns to compare and create analysis\n",
    "df5 = pd.get_dummies(df4, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df5.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
